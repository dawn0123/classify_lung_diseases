{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('sample/Data_Entry_2017.csv')\n",
    "\n",
    "diseases = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
    "#Number diseases\n",
    "for disease in diseases :\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "# #test to perfect\n",
    "# df = df.drop(df[df['Emphysema']==0][:-127].index.values)\n",
    "    \n",
    "#remove Y after age\n",
    "df['Age']=df['Patient Age'].apply(lambda x: x[:-1]).astype(int)\n",
    "df['Age Type']=df['Patient Age'].apply(lambda x: x[-1:])\n",
    "df.loc[df['Age Type']=='M',['Age']] = df[df['Age Type']=='M']['Age'].apply(lambda x: round(x/12.)).astype(int)\n",
    "df.loc[df['Age Type']=='D',['Age']] = df[df['Age Type']=='D']['Age'].apply(lambda x: round(x/365.)).astype(int)\n",
    "# remove outliers\n",
    "df = df.drop(df['Age'].sort_values(ascending=False).head(16).index)\n",
    "df['Age'] = df['Age']/df['Age'].max()\n",
    "\n",
    "#one hot data\n",
    "# df = df.drop(df.index[4242])\n",
    "df = df.join(pd.get_dummies(df['Patient Gender']))\n",
    "df = df.join(pd.get_dummies(df['View Position']))\n",
    "\n",
    "#random samples\n",
    "df = shuffle(df)\n",
    "\n",
    "#get other data\n",
    "data = df[['Age', 'F', 'M', 'AP', 'PA']]\n",
    "data = np.array(data)\n",
    "\n",
    "labels = df[diseases].as_matrix()\n",
    "files_list = ('sample/images/' + df['Image Index']).tolist()\n",
    "\n",
    "# #test to perfect\n",
    "# labelB = df['Emphysema'].tolist()\n",
    "\n",
    "labelB = (df[diseases].sum(axis=1)>0).tolist()\n",
    "labelB = np.array(labelB, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aind2/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "100%|██████████| 89600/89600 [21:25<00:00, 69.71it/s]\n",
      "100%|██████████| 11200/11200 [02:46<00:00, 67.31it/s]\n",
      "100%|██████████| 11304/11304 [02:35<00:00, 72.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path, shape):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=shape)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)/255\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, shape):\n",
    "    list_of_tensors = [path_to_tensor(img_path, shape) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "train_labels = labelB[:89600][:, np.newaxis]\n",
    "valid_labels = labelB[89600:100800][:, np.newaxis]\n",
    "test_labels = labelB[100800:][:, np.newaxis]\n",
    "\n",
    "train_data = data[:89600]\n",
    "valid_data = data[89600:100800]\n",
    "test_data = data[100800:]\n",
    "\n",
    "img_shape = (64, 64)\n",
    "train_tensors = paths_to_tensor(files_list[:89600], shape = img_shape)\n",
    "valid_tensors = paths_to_tensor(files_list[89600:100800], shape = img_shape)\n",
    "test_tensors = paths_to_tensor(files_list[100800:], shape = img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "57040896/58889256 [============================>.] - ETA: 0s ETA: _________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 537445    \n",
      "=================================================================\n",
      "Total params: 15,252,133\n",
      "Trainable params: 15,252,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 537,445\n",
      "Trainable params: 537,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers, applications, optimizers, initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# VGG16\n",
    "# resnet50.ResNet50\n",
    "# inception_v3.InceptionV3 299x299\n",
    "# inception_resnet_v2.InceptionResNetV2 299x299\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=train_tensors.shape[1:])\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "# add_model.add(Conv2D(filters=512, \n",
    "#                  kernel_size=4, \n",
    "#                  strides=2, \n",
    "# #                  kernel_regularizer=regularizers.l2(0.01),\n",
    "# #                  activity_regularizer=regularizers.l1(0.01),\n",
    "#                  kernel_initializer=initializers.random_normal(stddev=0.01), \n",
    "#                  padding='same', \n",
    "#                  activation='relu', \n",
    "#                  input_shape=base_model.output_shape[1:]))\n",
    "# # add_model.add(MaxPooling2D(pool_size=2))\n",
    "# add_model.add(BatchNormalization())\n",
    "# add_model.add(Flatten())\n",
    "# add_model.add(Dropout(0.2))\n",
    "# add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(50, activation='relu'))\n",
    "add_model.add(Dropout(0.2))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "model.summary()\n",
    "add_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy',\n",
    "                      precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6434 - acc: 0.6359 - precision: 0.6261 - recall: 0.5302 - fbeta_score: 0.5910Epoch 00000: val_loss improved from inf to 0.60848, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 384s - loss: 0.6433 - acc: 0.6360 - precision: 0.6261 - recall: 0.5302 - fbeta_score: 0.5911 - val_loss: 0.6085 - val_acc: 0.6794 - val_precision: 0.6966 - val_recall: 0.5468 - val_fbeta_score: 0.6519\n",
      "Epoch 2/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6203 - acc: 0.6693 - precision: 0.6620 - recall: 0.5899 - fbeta_score: 0.6364Epoch 00001: val_loss improved from 0.60848 to 0.59925, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 386s - loss: 0.6203 - acc: 0.6693 - precision: 0.6620 - recall: 0.5899 - fbeta_score: 0.6364 - val_loss: 0.5993 - val_acc: 0.6864 - val_precision: 0.7023 - val_recall: 0.5623 - val_fbeta_score: 0.6609\n",
      "Epoch 3/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6753 - precision: 0.6657 - recall: 0.6047 - fbeta_score: 0.6439Epoch 00002: val_loss improved from 0.59925 to 0.59694, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 386s - loss: 0.6141 - acc: 0.6753 - precision: 0.6658 - recall: 0.6047 - fbeta_score: 0.6439 - val_loss: 0.5969 - val_acc: 0.6945 - val_precision: 0.6972 - val_recall: 0.5999 - val_fbeta_score: 0.6688\n",
      "Epoch 4/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6789 - precision: 0.6668 - recall: 0.6136 - fbeta_score: 0.6480Epoch 00003: val_loss did not improve\n",
      "2800/2800 [==============================] - 384s - loss: 0.6106 - acc: 0.6790 - precision: 0.6668 - recall: 0.6136 - fbeta_score: 0.6480 - val_loss: 0.5982 - val_acc: 0.6871 - val_precision: 0.7096 - val_recall: 0.5453 - val_fbeta_score: 0.6610\n",
      "Epoch 5/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6824 - precision: 0.6707 - recall: 0.6179 - fbeta_score: 0.6520Epoch 00004: val_loss improved from 0.59694 to 0.59520, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 387s - loss: 0.6081 - acc: 0.6824 - precision: 0.6708 - recall: 0.6179 - fbeta_score: 0.6520 - val_loss: 0.5952 - val_acc: 0.6961 - val_precision: 0.6726 - val_recall: 0.6674 - val_fbeta_score: 0.6667\n",
      "Epoch 6/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6061 - acc: 0.6836 - precision: 0.6726 - recall: 0.6185 - fbeta_score: 0.6535Epoch 00005: val_loss improved from 0.59520 to 0.59270, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 386s - loss: 0.6061 - acc: 0.6836 - precision: 0.6726 - recall: 0.6185 - fbeta_score: 0.6535 - val_loss: 0.5927 - val_acc: 0.6959 - val_precision: 0.6715 - val_recall: 0.6710 - val_fbeta_score: 0.6665\n",
      "Epoch 7/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6037 - acc: 0.6837 - precision: 0.6736 - recall: 0.6166 - fbeta_score: 0.6535Epoch 00006: val_loss improved from 0.59270 to 0.59153, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 383s - loss: 0.6037 - acc: 0.6837 - precision: 0.6735 - recall: 0.6166 - fbeta_score: 0.6535 - val_loss: 0.5915 - val_acc: 0.6951 - val_precision: 0.7008 - val_recall: 0.5926 - val_fbeta_score: 0.6702\n",
      "Epoch 8/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.6856 - precision: 0.6738 - recall: 0.6207 - fbeta_score: 0.6555Epoch 00007: val_loss did not improve\n",
      "2800/2800 [==============================] - 383s - loss: 0.6027 - acc: 0.6856 - precision: 0.6738 - recall: 0.6207 - fbeta_score: 0.6554 - val_loss: 0.5923 - val_acc: 0.6967 - val_precision: 0.6924 - val_recall: 0.6186 - val_fbeta_score: 0.6706\n",
      "Epoch 9/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.6881 - precision: 0.6753 - recall: 0.6274 - fbeta_score: 0.6580Epoch 00008: val_loss improved from 0.59153 to 0.59117, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 384s - loss: 0.6017 - acc: 0.6880 - precision: 0.6753 - recall: 0.6274 - fbeta_score: 0.6580 - val_loss: 0.5912 - val_acc: 0.6978 - val_precision: 0.6960 - val_recall: 0.6147 - val_fbeta_score: 0.6721\n",
      "Epoch 10/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6883 - precision: 0.6756 - recall: 0.6259 - fbeta_score: 0.6582Epoch 00009: val_loss did not improve\n",
      "2800/2800 [==============================] - 383s - loss: 0.6003 - acc: 0.6883 - precision: 0.6756 - recall: 0.6259 - fbeta_score: 0.6582 - val_loss: 0.5912 - val_acc: 0.6968 - val_precision: 0.6682 - val_recall: 0.6821 - val_fbeta_score: 0.6664\n",
      "Epoch 11/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5995 - acc: 0.6901 - precision: 0.6776 - recall: 0.6290 - fbeta_score: 0.6606Epoch 00010: val_loss did not improve\n",
      "2800/2800 [==============================] - 384s - loss: 0.5995 - acc: 0.6901 - precision: 0.6776 - recall: 0.6291 - fbeta_score: 0.6606 - val_loss: 0.5922 - val_acc: 0.6975 - val_precision: 0.6691 - val_recall: 0.6820 - val_fbeta_score: 0.6672\n",
      "Epoch 12/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5976 - acc: 0.6918 - precision: 0.6791 - recall: 0.6313 - fbeta_score: 0.6615Epoch 00011: val_loss did not improve\n",
      "2800/2800 [==============================] - 385s - loss: 0.5976 - acc: 0.6918 - precision: 0.6791 - recall: 0.6312 - fbeta_score: 0.6615 - val_loss: 0.6020 - val_acc: 0.6856 - val_precision: 0.7405 - val_recall: 0.4893 - val_fbeta_score: 0.6615\n",
      "Epoch 13/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5979 - acc: 0.6923 - precision: 0.6809 - recall: 0.6290 - fbeta_score: 0.6630Epoch 00012: val_loss improved from 0.59117 to 0.58741, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 384s - loss: 0.5979 - acc: 0.6922 - precision: 0.6808 - recall: 0.6289 - fbeta_score: 0.6630 - val_loss: 0.5874 - val_acc: 0.7013 - val_precision: 0.6913 - val_recall: 0.6397 - val_fbeta_score: 0.6748\n",
      "Epoch 14/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.6931 - precision: 0.6829 - recall: 0.6309 - fbeta_score: 0.6645Epoch 00013: val_loss improved from 0.58741 to 0.58626, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 385s - loss: 0.5970 - acc: 0.6931 - precision: 0.6829 - recall: 0.6309 - fbeta_score: 0.6645 - val_loss: 0.5863 - val_acc: 0.6979 - val_precision: 0.6888 - val_recall: 0.6324 - val_fbeta_score: 0.6712\n",
      "Epoch 15/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5963 - acc: 0.6924 - precision: 0.6803 - recall: 0.6333 - fbeta_score: 0.6636Epoch 00014: val_loss improved from 0.58626 to 0.58613, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 385s - loss: 0.5963 - acc: 0.6924 - precision: 0.6803 - recall: 0.6333 - fbeta_score: 0.6637 - val_loss: 0.5861 - val_acc: 0.7004 - val_precision: 0.6844 - val_recall: 0.6481 - val_fbeta_score: 0.6717\n",
      "Epoch 16/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.6949 - precision: 0.6819 - recall: 0.6400 - fbeta_score: 0.6665Epoch 00015: val_loss improved from 0.58613 to 0.58596, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 385s - loss: 0.5951 - acc: 0.6950 - precision: 0.6819 - recall: 0.6400 - fbeta_score: 0.6665 - val_loss: 0.5860 - val_acc: 0.7013 - val_precision: 0.7025 - val_recall: 0.6119 - val_fbeta_score: 0.6763\n",
      "Epoch 17/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.6939 - precision: 0.6807 - recall: 0.6381 - fbeta_score: 0.6647Epoch 00016: val_loss did not improve\n",
      "2800/2800 [==============================] - 385s - loss: 0.5951 - acc: 0.6939 - precision: 0.6807 - recall: 0.6381 - fbeta_score: 0.6647 - val_loss: 0.5885 - val_acc: 0.6981 - val_precision: 0.7165 - val_recall: 0.5711 - val_fbeta_score: 0.6749\n",
      "Epoch 18/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5938 - acc: 0.6955 - precision: 0.6831 - recall: 0.6353 - fbeta_score: 0.6663Epoch 00017: val_loss did not improve\n",
      "2800/2800 [==============================] - 385s - loss: 0.5938 - acc: 0.6955 - precision: 0.6830 - recall: 0.6354 - fbeta_score: 0.6663 - val_loss: 0.5902 - val_acc: 0.7011 - val_precision: 0.6698 - val_recall: 0.6975 - val_fbeta_score: 0.6708\n",
      "Epoch 19/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.6960 - precision: 0.6837 - recall: 0.6369 - fbeta_score: 0.6672Epoch 00018: val_loss did not improve\n",
      "2800/2800 [==============================] - 384s - loss: 0.5928 - acc: 0.6960 - precision: 0.6838 - recall: 0.6369 - fbeta_score: 0.6672 - val_loss: 0.5887 - val_acc: 0.7021 - val_precision: 0.6933 - val_recall: 0.6374 - val_fbeta_score: 0.6757\n",
      "Epoch 20/20\n",
      "2799/2800 [============================>.] - ETA: 0s - loss: 0.5924 - acc: 0.6967 - precision: 0.6842 - recall: 0.6392 - fbeta_score: 0.6681Epoch 00019: val_loss improved from 0.58596 to 0.58356, saving model to saved_models/pretrainedVGG.best.from_scratch.hdf5\n",
      "2800/2800 [==============================] - 385s - loss: 0.5925 - acc: 0.6967 - precision: 0.6842 - recall: 0.6392 - fbeta_score: 0.6681 - val_loss: 0.5836 - val_acc: 0.7024 - val_precision: 0.6902 - val_recall: 0.6467 - val_fbeta_score: 0.6753\n",
      "training time: 128.38 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_pretrained_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/pretrainedVGG.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# model.fit(train_tensors, train_labels, \n",
    "#           validation_data=(valid_tensors, valid_labels),\n",
    "#           epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "def train_generator(x, y, batch_size):\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                        samplewise_center=False,  # set each sample mean to 0\n",
    "                        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                        samplewise_std_normalization=False,  # divide each input by its std\n",
    "                        zca_whitening=False,  # apply ZCA whitening\n",
    "                        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                        horizontal_flip=True,  # randomly flip images\n",
    "                        vertical_flip=False)  # randomly flip images\n",
    "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            yield [x_batch, y_batch]\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "model.fit_generator(generator=train_generator(train_tensors, train_labels, batch_size),\n",
    "                    steps_per_epoch=int(train_labels.shape[0] / batch_size),\n",
    "                    validation_data=(valid_tensors, valid_labels),\n",
    "                    epochs=epochs, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/pretrainedVGG.best.from_scratch.hdf5')\n",
    "prediction = model.predict(test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.675466 %\n",
      "Recall: 0.619285 %\n",
      "Fscore: 0.663429 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68763268"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                       K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86135578],\n",
       "       [ 0.38395363],\n",
       "       [ 0.49149001],\n",
       "       [ 0.41301057],\n",
       "       [ 0.69047374],\n",
       "       [ 0.59208387],\n",
       "       [ 0.47005421],\n",
       "       [ 0.7447359 ],\n",
       "       [ 0.76747203],\n",
       "       [ 0.47276884],\n",
       "       [ 0.65790629],\n",
       "       [ 0.80368102],\n",
       "       [ 0.55971575],\n",
       "       [ 0.62390733],\n",
       "       [ 0.79730672],\n",
       "       [ 0.45695341],\n",
       "       [ 0.2720097 ],\n",
       "       [ 0.76029223],\n",
       "       [ 0.39768952],\n",
       "       [ 0.19952367],\n",
       "       [ 0.84283119],\n",
       "       [ 0.75410837],\n",
       "       [ 0.5692758 ],\n",
       "       [ 0.73594892],\n",
       "       [ 0.39063299],\n",
       "       [ 0.32207093],\n",
       "       [ 0.4930805 ],\n",
       "       [ 0.4202663 ],\n",
       "       [ 0.47011665],\n",
       "       [ 0.39033732]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with extra data and spacial transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1_input (InputLayer)      (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_1_input[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 64, 64, 3)     12          lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "spatial_transformer_1 (SpatialTr (None, 64, 64, 3)     247270      batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 2048)          14714688    spatial_transformer_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 2053)          0           model_2[1][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 2053)          0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 256)           525824      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 256)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             257         dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 15,488,051\n",
      "Trainable params: 15,488,045\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"in...)`\n",
      "/home/aind2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:73: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, merge, concatenate\n",
    "from spatial_transformer import SpatialTransformer\n",
    "\n",
    "def locnet():\n",
    "    b = np.zeros((2, 3), dtype='float32')\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    W = np.zeros((64, 6), dtype='float32')\n",
    "    weights = [W, b.flatten()]\n",
    "    locnet = Sequential()\n",
    "\n",
    "    locnet.add(Conv2D(16, (7, 7), padding='valid', input_shape=train_tensors.shape[1:]))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    locnet.add(Conv2D(32, (5, 5), padding='valid'))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    locnet.add(Conv2D(64, (3, 3), padding='valid'))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    locnet.add(Flatten())\n",
    "    locnet.add(Dense(128, activation='elu'))\n",
    "    locnet.add(Dense(64, activation='elu'))\n",
    "    locnet.add(Dense(6, weights=weights))\n",
    "\n",
    "    return locnet\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=train_tensors.shape[1:])\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "\n",
    "added0_model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "\n",
    "stn_model = Sequential()\n",
    "stn_model.add(Lambda(\n",
    "    lambda x: 2*x - 1.,\n",
    "    input_shape=train_tensors.shape[1:],\n",
    "    output_shape=train_tensors.shape[1:]))\n",
    "stn_model.add(BatchNormalization())\n",
    "stn_model.add(SpatialTransformer(localization_net=locnet(),\n",
    "                                 output_size=train_tensors.shape[1:3]))\n",
    "\n",
    "added_model = Model(inputs=stn_model.input, outputs=added0_model(stn_model.output))\n",
    "\n",
    "inp = Input(batch_shape=(None, train_data.shape[1]))\n",
    "# out = Dense(8)(inp)\n",
    "extra_model = Model(input=inp, output=inp)\n",
    "\n",
    "x = concatenate([added_model.output,\n",
    "           extra_model.output])\n",
    "\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model =  Model(input=[added_model.input,\n",
    "                extra_model.input],\n",
    "                output=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy',\n",
    "                      precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89600 samples, validate on 11200 samples\n",
      "Epoch 1/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.6440 - acc: 0.6434 - precision: 0.6297 - recall: 0.5685 - fbeta_score: 0.6069Epoch 00000: val_loss improved from inf to 0.61177, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 431s - loss: 0.6440 - acc: 0.6434 - precision: 0.6296 - recall: 0.5685 - fbeta_score: 0.6068 - val_loss: 0.6118 - val_acc: 0.6751 - val_precision: 0.6260 - val_recall: 0.7379 - val_fbeta_score: 0.6418\n",
      "Epoch 2/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.6159 - acc: 0.6759 - precision: 0.6647 - recall: 0.6083 - fbeta_score: 0.6441Epoch 00001: val_loss improved from 0.61177 to 0.59526, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 433s - loss: 0.6160 - acc: 0.6760 - precision: 0.6647 - recall: 0.6083 - fbeta_score: 0.6441 - val_loss: 0.5953 - val_acc: 0.6919 - val_precision: 0.6656 - val_recall: 0.6749 - val_fbeta_score: 0.6624\n",
      "Epoch 3/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.6099 - acc: 0.6819 - precision: 0.6704 - recall: 0.6165 - fbeta_score: 0.6511Epoch 00002: val_loss improved from 0.59526 to 0.59411, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 433s - loss: 0.6099 - acc: 0.6819 - precision: 0.6704 - recall: 0.6165 - fbeta_score: 0.6511 - val_loss: 0.5941 - val_acc: 0.6946 - val_precision: 0.6575 - val_recall: 0.7096 - val_fbeta_score: 0.6629\n",
      "Epoch 4/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.6858 - precision: 0.6747 - recall: 0.6246 - fbeta_score: 0.6565Epoch 00003: val_loss improved from 0.59411 to 0.59090, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 432s - loss: 0.6062 - acc: 0.6858 - precision: 0.6746 - recall: 0.6246 - fbeta_score: 0.6564 - val_loss: 0.5909 - val_acc: 0.6950 - val_precision: 0.6724 - val_recall: 0.6646 - val_fbeta_score: 0.6660\n",
      "Epoch 5/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.6014 - acc: 0.6898 - precision: 0.6767 - recall: 0.6320 - fbeta_score: 0.6601Epoch 00004: val_loss improved from 0.59090 to 0.58927, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 432s - loss: 0.6014 - acc: 0.6899 - precision: 0.6769 - recall: 0.6321 - fbeta_score: 0.6602 - val_loss: 0.5893 - val_acc: 0.6987 - val_precision: 0.6999 - val_recall: 0.6103 - val_fbeta_score: 0.6738\n",
      "Epoch 6/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6922 - precision: 0.6794 - recall: 0.6359 - fbeta_score: 0.6633Epoch 00005: val_loss improved from 0.58927 to 0.58893, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 436s - loss: 0.5981 - acc: 0.6922 - precision: 0.6794 - recall: 0.6359 - fbeta_score: 0.6633 - val_loss: 0.5889 - val_acc: 0.6996 - val_precision: 0.6850 - val_recall: 0.6499 - val_fbeta_score: 0.6724\n",
      "Epoch 7/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6950 - precision: 0.6819 - recall: 0.6391 - fbeta_score: 0.6660Epoch 00006: val_loss improved from 0.58893 to 0.58689, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 434s - loss: 0.5969 - acc: 0.6950 - precision: 0.6819 - recall: 0.6391 - fbeta_score: 0.6661 - val_loss: 0.5869 - val_acc: 0.7002 - val_precision: 0.6818 - val_recall: 0.6582 - val_fbeta_score: 0.6717\n",
      "Epoch 8/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5955 - acc: 0.6950 - precision: 0.6829 - recall: 0.6374 - fbeta_score: 0.6664Epoch 00007: val_loss improved from 0.58689 to 0.58673, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 433s - loss: 0.5954 - acc: 0.6950 - precision: 0.6830 - recall: 0.6374 - fbeta_score: 0.6665 - val_loss: 0.5867 - val_acc: 0.7001 - val_precision: 0.6826 - val_recall: 0.6517 - val_fbeta_score: 0.6708\n",
      "Epoch 9/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5947 - acc: 0.6969 - precision: 0.6849 - recall: 0.6393 - fbeta_score: 0.6684Epoch 00008: val_loss improved from 0.58673 to 0.58586, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 433s - loss: 0.5947 - acc: 0.6968 - precision: 0.6849 - recall: 0.6393 - fbeta_score: 0.6684 - val_loss: 0.5859 - val_acc: 0.7046 - val_precision: 0.6858 - val_recall: 0.6695 - val_fbeta_score: 0.6772\n",
      "Epoch 10/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.6982 - precision: 0.6857 - recall: 0.6414 - fbeta_score: 0.6699Epoch 00009: val_loss did not improve\n",
      "89600/89600 [==============================] - 433s - loss: 0.5922 - acc: 0.6982 - precision: 0.6857 - recall: 0.6415 - fbeta_score: 0.6699 - val_loss: 0.5874 - val_acc: 0.7029 - val_precision: 0.6823 - val_recall: 0.6655 - val_fbeta_score: 0.6738\n",
      "Epoch 11/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5896 - acc: 0.6997 - precision: 0.6863 - recall: 0.6466 - fbeta_score: 0.6713Epoch 00010: val_loss improved from 0.58586 to 0.58575, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 432s - loss: 0.5896 - acc: 0.6997 - precision: 0.6863 - recall: 0.6467 - fbeta_score: 0.6713 - val_loss: 0.5858 - val_acc: 0.6957 - val_precision: 0.6546 - val_recall: 0.7254 - val_fbeta_score: 0.6635\n",
      "Epoch 12/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.7019 - precision: 0.6880 - recall: 0.6519 - fbeta_score: 0.6740Epoch 00011: val_loss did not improve\n",
      "89600/89600 [==============================] - 432s - loss: 0.5882 - acc: 0.7019 - precision: 0.6881 - recall: 0.6519 - fbeta_score: 0.6741 - val_loss: 0.5906 - val_acc: 0.7025 - val_precision: 0.6679 - val_recall: 0.7083 - val_fbeta_score: 0.6712\n",
      "Epoch 13/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5878 - acc: 0.7020 - precision: 0.6884 - recall: 0.6512 - fbeta_score: 0.6742Epoch 00012: val_loss improved from 0.58575 to 0.58157, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 434s - loss: 0.5878 - acc: 0.7020 - precision: 0.6884 - recall: 0.6512 - fbeta_score: 0.6742 - val_loss: 0.5816 - val_acc: 0.7040 - val_precision: 0.6925 - val_recall: 0.6463 - val_fbeta_score: 0.6773\n",
      "Epoch 14/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.7031 - precision: 0.6898 - recall: 0.6500 - fbeta_score: 0.6748Epoch 00013: val_loss did not improve\n",
      "89600/89600 [==============================] - 433s - loss: 0.5854 - acc: 0.7031 - precision: 0.6898 - recall: 0.6500 - fbeta_score: 0.6747 - val_loss: 0.5823 - val_acc: 0.7046 - val_precision: 0.7109 - val_recall: 0.6089 - val_fbeta_score: 0.6813\n",
      "Epoch 15/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.7038 - precision: 0.6913 - recall: 0.6496 - fbeta_score: 0.6759Epoch 00014: val_loss did not improve\n",
      "89600/89600 [==============================] - 433s - loss: 0.5852 - acc: 0.7038 - precision: 0.6913 - recall: 0.6497 - fbeta_score: 0.6758 - val_loss: 0.5818 - val_acc: 0.7092 - val_precision: 0.7162 - val_recall: 0.6137 - val_fbeta_score: 0.6867\n",
      "Epoch 16/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.7035 - precision: 0.6929 - recall: 0.6483 - fbeta_score: 0.6768Epoch 00015: val_loss improved from 0.58157 to 0.58047, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 434s - loss: 0.5851 - acc: 0.7035 - precision: 0.6928 - recall: 0.6483 - fbeta_score: 0.6767 - val_loss: 0.5805 - val_acc: 0.7067 - val_precision: 0.6860 - val_recall: 0.6715 - val_fbeta_score: 0.6782\n",
      "Epoch 17/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5831 - acc: 0.7065 - precision: 0.6947 - recall: 0.6523 - fbeta_score: 0.6793Epoch 00016: val_loss did not improve\n",
      "89600/89600 [==============================] - 431s - loss: 0.5831 - acc: 0.7064 - precision: 0.6947 - recall: 0.6523 - fbeta_score: 0.6793 - val_loss: 0.5845 - val_acc: 0.7036 - val_precision: 0.6778 - val_recall: 0.6839 - val_fbeta_score: 0.6740\n",
      "Epoch 18/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.7064 - precision: 0.6930 - recall: 0.6550 - fbeta_score: 0.6788Epoch 00017: val_loss did not improve\n",
      "89600/89600 [==============================] - 432s - loss: 0.5826 - acc: 0.7064 - precision: 0.6930 - recall: 0.6550 - fbeta_score: 0.6789 - val_loss: 0.5806 - val_acc: 0.7042 - val_precision: 0.6711 - val_recall: 0.7055 - val_fbeta_score: 0.6731\n",
      "Epoch 19/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.7080 - precision: 0.6943 - recall: 0.6580 - fbeta_score: 0.6807Epoch 00018: val_loss improved from 0.58047 to 0.57944, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 434s - loss: 0.5810 - acc: 0.7080 - precision: 0.6943 - recall: 0.6579 - fbeta_score: 0.6807 - val_loss: 0.5794 - val_acc: 0.7099 - val_precision: 0.7189 - val_recall: 0.6120 - val_fbeta_score: 0.6881\n",
      "Epoch 20/20\n",
      "89568/89600 [============================>.] - ETA: 0s - loss: 0.5779 - acc: 0.7084 - precision: 0.6955 - recall: 0.6566 - fbeta_score: 0.6811Epoch 00019: val_loss improved from 0.57944 to 0.57674, saving model to saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5\n",
      "89600/89600 [==============================] - 433s - loss: 0.5779 - acc: 0.7085 - precision: 0.6956 - recall: 0.6566 - fbeta_score: 0.6812 - val_loss: 0.5767 - val_acc: 0.7108 - val_precision: 0.7038 - val_recall: 0.6468 - val_fbeta_score: 0.6860\n",
      "training time: 144.48 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_pretrained_extradata_stn_CNN.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit([train_tensors, train_data], train_labels, \n",
    "          validation_data=([valid_tensors, valid_data], valid_labels),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# def train_generator(x, y, batch_size):\n",
    "#         train_datagen = ImageDataGenerator(\n",
    "#                         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#                         samplewise_center=False,  # set each sample mean to 0\n",
    "#                         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#                         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#                         zca_whitening=False,  # apply ZCA whitening\n",
    "#                         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#                         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#                         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#                         horizontal_flip=True,  # randomly flip images\n",
    "#                         vertical_flip=False)  # randomly flip images\n",
    "#         generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "#         while 1:\n",
    "#             x_batch, y_batch = generator.next()\n",
    "#             yield [x_batch, y_batch]\n",
    "\n",
    "# # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "# model.fit_generator(generator=train_generator(train_tensors, train_labels, batch_size),\n",
    "#                     steps_per_epoch=int(train_labels.shape[0] / batch_size),\n",
    "#                     validation_data=(valid_tensors, valid_labels),\n",
    "#                     epochs=epochs, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/log_pretrained_extradata_stn_CNN.best.from_scratch.hdf5')\n",
    "prediction = model.predict([test_tensors, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.684010 %\n",
      "Recall: 0.621206 %\n",
      "Fscore: 0.670454 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69338286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                       K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
