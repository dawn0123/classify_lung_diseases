{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With rgb images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_filename = \"data_preprocessed/train_data_sample_rgb.p\"\n",
    "(train_labels, train_data, train_tensors) = pickle.load(open(train_filename, mode='rb'))\n",
    "\n",
    "valid_filename = \"data_preprocessed/valid_data_sample_rgb.p\"\n",
    "(valid_labels, valid_data, valid_tensors) = pickle.load(open(valid_filename, mode='rb'))\n",
    "\n",
    "test_filename = \"data_preprocessed/test_data_sample_rgb.p\"\n",
    "(test_labels, test_data, test_tensors) = pickle.load(open(test_filename, mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 322,793\n",
      "Trainable params: 322,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers, initializers, optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=7,\n",
    "                 padding='same', \n",
    "                 activation='relu', \n",
    "                 input_shape=train_tensors.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=5,\n",
    "                 strides=2,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', \n",
    "              metrics=[precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5),\n",
    "                      'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3400 samples, validate on 1100 samples\n",
      "Epoch 1/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6880 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5457Epoch 00001: val_loss improved from inf to 0.68814, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 6s 2ms/step - loss: 0.6878 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5465 - val_loss: 0.6881 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5482\n",
      "Epoch 2/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6853 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5469Epoch 00002: val_loss improved from 0.68814 to 0.68352, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 637us/step - loss: 0.6853 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5465 - val_loss: 0.6835 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5482\n",
      "Epoch 3/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6822 - precision: 0.0660 - recall: 0.0078 - fbeta_score: 0.0256 - acc: 0.5478Epoch 00003: val_loss improved from 0.68352 to 0.68176, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 638us/step - loss: 0.6821 - precision: 0.0659 - recall: 0.0078 - fbeta_score: 0.0256 - acc: 0.5479 - val_loss: 0.6818 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5482\n",
      "Epoch 4/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6778 - precision: 0.2974 - recall: 0.0929 - fbeta_score: 0.1770 - acc: 0.5643Epoch 00004: val_loss improved from 0.68176 to 0.67342, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 636us/step - loss: 0.6778 - precision: 0.2979 - recall: 0.0932 - fbeta_score: 0.1776 - acc: 0.5641 - val_loss: 0.6734 - val_precision: 0.6478 - val_recall: 0.3187 - val_fbeta_score: 0.5230 - val_acc: 0.6082\n",
      "Epoch 5/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6695 - precision: 0.5334 - recall: 0.2741 - fbeta_score: 0.3894 - acc: 0.5843Epoch 00005: val_loss improved from 0.67342 to 0.66195, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 634us/step - loss: 0.6696 - precision: 0.5334 - recall: 0.2740 - fbeta_score: 0.3894 - acc: 0.5841 - val_loss: 0.6619 - val_precision: 0.6358 - val_recall: 0.3035 - val_fbeta_score: 0.5063 - val_acc: 0.6018\n",
      "Epoch 6/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6619 - precision: 0.6025 - recall: 0.3949 - fbeta_score: 0.4957 - acc: 0.5970Epoch 00006: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 629us/step - loss: 0.6614 - precision: 0.6011 - recall: 0.3940 - fbeta_score: 0.4945 - acc: 0.5976 - val_loss: 0.8364 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5482\n",
      "Epoch 7/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6571 - precision: 0.6038 - recall: 0.4296 - fbeta_score: 0.5116 - acc: 0.6067Epoch 00007: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 630us/step - loss: 0.6567 - precision: 0.6047 - recall: 0.4302 - fbeta_score: 0.5126 - acc: 0.6074 - val_loss: 0.6649 - val_precision: 0.6424 - val_recall: 0.2262 - val_fbeta_score: 0.4548 - val_acc: 0.5936\n",
      "Epoch 8/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6537 - precision: 0.6049 - recall: 0.4763 - fbeta_score: 0.5451 - acc: 0.6223Epoch 00008: val_loss improved from 0.66195 to 0.65951, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 636us/step - loss: 0.6539 - precision: 0.6049 - recall: 0.4769 - fbeta_score: 0.5453 - acc: 0.6224 - val_loss: 0.6595 - val_precision: 0.5727 - val_recall: 0.6779 - val_fbeta_score: 0.5868 - val_acc: 0.6209\n",
      "Epoch 9/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6503 - precision: 0.6183 - recall: 0.4933 - fbeta_score: 0.5667 - acc: 0.6312Epoch 00009: val_loss improved from 0.65951 to 0.65006, saving model to saved_models/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 638us/step - loss: 0.6502 - precision: 0.6186 - recall: 0.4939 - fbeta_score: 0.5672 - acc: 0.6315 - val_loss: 0.6501 - val_precision: 0.6236 - val_recall: 0.5744 - val_fbeta_score: 0.6056 - val_acc: 0.6445\n",
      "Epoch 10/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6486 - precision: 0.6144 - recall: 0.4919 - fbeta_score: 0.5607 - acc: 0.6197Epoch 00010: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 633us/step - loss: 0.6491 - precision: 0.6153 - recall: 0.4912 - fbeta_score: 0.5607 - acc: 0.6194 - val_loss: 0.6955 - val_precision: 0.4951 - val_recall: 0.8959 - val_fbeta_score: 0.5416 - val_acc: 0.5382\n",
      "Epoch 11/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6462 - precision: 0.6221 - recall: 0.5064 - fbeta_score: 0.5710 - acc: 0.6277Epoch 00011: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 633us/step - loss: 0.6461 - precision: 0.6218 - recall: 0.5076 - fbeta_score: 0.5710 - acc: 0.6276 - val_loss: 0.6587 - val_precision: 0.6374 - val_recall: 0.2935 - val_fbeta_score: 0.5025 - val_acc: 0.6027\n",
      "Epoch 12/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6435 - precision: 0.6175 - recall: 0.4894 - fbeta_score: 0.5614 - acc: 0.6262Epoch 00012: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 632us/step - loss: 0.6434 - precision: 0.6172 - recall: 0.4890 - fbeta_score: 0.5612 - acc: 0.6262 - val_loss: 0.6522 - val_precision: 0.6512 - val_recall: 0.3691 - val_fbeta_score: 0.5529 - val_acc: 0.6209\n",
      "Epoch 00012: early stopping\n",
      "training time: 0.50 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_bCNN_rgb.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/bCNN.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, valid_labels),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/bCNN.best.from_scratch.hdf5')\n",
    "prediction = model.predict(test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.617234 %\n",
      "Recall: 0.588910 %\n",
      "Fscore: 0.611354 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50258511"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46597424],\n",
       "       [ 0.57600302],\n",
       "       [ 0.30108091],\n",
       "       [ 0.50593966],\n",
       "       [ 0.61561286],\n",
       "       [ 0.6416322 ],\n",
       "       [ 0.29955843],\n",
       "       [ 0.30611175],\n",
       "       [ 0.42266327],\n",
       "       [ 0.40697429],\n",
       "       [ 0.48799837],\n",
       "       [ 0.34801716],\n",
       "       [ 0.55648535],\n",
       "       [ 0.52279401],\n",
       "       [ 0.62823325],\n",
       "       [ 0.35642451],\n",
       "       [ 0.50304908],\n",
       "       [ 0.42197177],\n",
       "       [ 0.72991049],\n",
       "       [ 0.50801474],\n",
       "       [ 0.31001693],\n",
       "       [ 0.49956188],\n",
       "       [ 0.50922167],\n",
       "       [ 0.47676209],\n",
       "       [ 0.36952221],\n",
       "       [ 0.3691574 ],\n",
       "       [ 0.63229394],\n",
       "       [ 0.49165967],\n",
       "       [ 0.53164726],\n",
       "       [ 0.54903966]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.543257 %\n",
      "Recall: 0.816444 %\n",
      "Fscore: 0.582220 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.672000 %\n",
      "Recall: 0.321224 %\n",
      "Fscore: 0.551543 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.6\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_filename = \"data_preprocessed/train_data_sample_gray.p\"\n",
    "(train_labels, train_data, train_tensors) = pickle.load(open(train_filename, mode='rb'))\n",
    "\n",
    "valid_filename = \"data_preprocessed/valid_data_sample_gray.p\"\n",
    "(valid_labels, valid_data, valid_tensors) = pickle.load(open(valid_filename, mode='rb'))\n",
    "\n",
    "test_filename = \"data_preprocessed/test_data_sample_gray.p\"\n",
    "(test_labels, test_data, test_tensors) = pickle.load(open(test_filename, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 321,225\n",
      "Trainable params: 321,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers, initializers, optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=7,\n",
    "                 padding='same', \n",
    "                 activation='relu', \n",
    "                 input_shape=train_tensors.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=5,\n",
    "                 strides=2,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', \n",
    "              metrics=[precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5),\n",
    "                      'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3400 samples, validate on 1100 samples\n",
      "Epoch 1/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6900 - precision: 0.1182 - recall: 0.2178 - fbeta_score: 0.1266 - acc: 0.5373Epoch 00001: val_loss improved from inf to 0.69002, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 682us/step - loss: 0.6901 - precision: 0.1157 - recall: 0.2131 - fbeta_score: 0.1239 - acc: 0.5359 - val_loss: 0.6900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5291\n",
      "Epoch 2/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6877 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5405Epoch 00002: val_loss improved from 0.69002 to 0.68985, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 569us/step - loss: 0.6877 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5409 - val_loss: 0.6899 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5291\n",
      "Epoch 3/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6861 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5399Epoch 00003: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 563us/step - loss: 0.6859 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5409 - val_loss: 0.6921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5291\n",
      "Epoch 4/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6837 - precision: 0.0096 - recall: 7.3964e-04 - fbeta_score: 0.0028 - acc: 0.5406    Epoch 00004: val_loss improved from 0.68985 to 0.68468, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 574us/step - loss: 0.6837 - precision: 0.0141 - recall: 0.0014 - fbeta_score: 0.0049 - acc: 0.5403 - val_loss: 0.6847 - val_precision: 0.0727 - val_recall: 0.0063 - val_fbeta_score: 0.0230 - val_acc: 0.5309\n",
      "Epoch 5/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6802 - precision: 0.2212 - recall: 0.0330 - fbeta_score: 0.0913 - acc: 0.5473Epoch 00005: val_loss improved from 0.68468 to 0.68110, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 570us/step - loss: 0.6803 - precision: 0.2186 - recall: 0.0326 - fbeta_score: 0.0902 - acc: 0.5468 - val_loss: 0.6811 - val_precision: 0.2812 - val_recall: 0.0339 - val_fbeta_score: 0.1079 - val_acc: 0.5364\n",
      "Epoch 6/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6745 - precision: 0.5036 - recall: 0.1669 - fbeta_score: 0.3177 - acc: 0.5817Epoch 00006: val_loss improved from 0.68110 to 0.67981, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 569us/step - loss: 0.6746 - precision: 0.5105 - recall: 0.1685 - fbeta_score: 0.3214 - acc: 0.5809 - val_loss: 0.6798 - val_precision: 0.5527 - val_recall: 0.7384 - val_fbeta_score: 0.5775 - val_acc: 0.5891\n",
      "Epoch 7/20\n",
      "3296/3400 [============================>.] - ETA: 0s - loss: 0.6672 - precision: 0.6067 - recall: 0.3669 - fbeta_score: 0.4821 - acc: 0.6062Epoch 00007: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 563us/step - loss: 0.6667 - precision: 0.6079 - recall: 0.3663 - fbeta_score: 0.4841 - acc: 0.6076 - val_loss: 0.6825 - val_precision: 0.5411 - val_recall: 0.0988 - val_fbeta_score: 0.2625 - val_acc: 0.5491\n",
      "Epoch 8/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6620 - precision: 0.5974 - recall: 0.4096 - fbeta_score: 0.5063 - acc: 0.5983Epoch 00008: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 564us/step - loss: 0.6616 - precision: 0.5987 - recall: 0.4100 - fbeta_score: 0.5080 - acc: 0.5988 - val_loss: 0.7088 - val_precision: 0.4828 - val_recall: 0.9658 - val_fbeta_score: 0.5347 - val_acc: 0.4964\n",
      "Epoch 9/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6549 - precision: 0.6199 - recall: 0.4667 - fbeta_score: 0.5570 - acc: 0.6214Epoch 00009: val_loss improved from 0.67981 to 0.65802, saving model to saved_models/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 569us/step - loss: 0.6568 - precision: 0.6173 - recall: 0.4635 - fbeta_score: 0.5541 - acc: 0.6197 - val_loss: 0.6580 - val_precision: 0.6221 - val_recall: 0.4836 - val_fbeta_score: 0.5805 - val_acc: 0.6209\n",
      "Epoch 10/20\n",
      "3296/3400 [============================>.] - ETA: 0s - loss: 0.6548 - precision: 0.6294 - recall: 0.4779 - fbeta_score: 0.5588 - acc: 0.6204Epoch 00010: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 564us/step - loss: 0.6544 - precision: 0.6312 - recall: 0.4814 - fbeta_score: 0.5618 - acc: 0.6209 - val_loss: 0.6714 - val_precision: 0.5552 - val_recall: 0.7640 - val_fbeta_score: 0.5833 - val_acc: 0.5964\n",
      "Epoch 11/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6514 - precision: 0.6366 - recall: 0.5072 - fbeta_score: 0.5816 - acc: 0.6232Epoch 00011: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 564us/step - loss: 0.6521 - precision: 0.6321 - recall: 0.5051 - fbeta_score: 0.5780 - acc: 0.6215 - val_loss: 0.6751 - val_precision: 0.6973 - val_recall: 0.2211 - val_fbeta_score: 0.4559 - val_acc: 0.5773\n",
      "Epoch 12/20\n",
      "3296/3400 [============================>.] - ETA: 0s - loss: 0.6508 - precision: 0.6292 - recall: 0.4952 - fbeta_score: 0.5799 - acc: 0.6323Epoch 00012: val_loss did not improve\n",
      "3400/3400 [==============================] - 2s 565us/step - loss: 0.6498 - precision: 0.6315 - recall: 0.5001 - fbeta_score: 0.5829 - acc: 0.6335 - val_loss: 0.6675 - val_precision: 0.6483 - val_recall: 0.3281 - val_fbeta_score: 0.5318 - val_acc: 0.5991\n",
      "Epoch 00012: early stopping\n",
      "training time: 0.40 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "log = CSVLogger('saved_models/log_bCNN_gray.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/bCNN_gray.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, valid_labels),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/bCNN_gray.best.from_scratch.hdf5')\n",
    "prediction = model.predict(test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.577114 %\n",
      "Recall: 0.480331 %\n",
      "Fscore: 0.554758 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51713276"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3081094 ],\n",
       "       [ 0.24159142],\n",
       "       [ 0.52262437],\n",
       "       [ 0.59462857],\n",
       "       [ 0.3100515 ],\n",
       "       [ 0.62393486],\n",
       "       [ 0.47555083],\n",
       "       [ 0.48481095],\n",
       "       [ 0.47963724],\n",
       "       [ 0.46049529],\n",
       "       [ 0.52123272],\n",
       "       [ 0.38751996],\n",
       "       [ 0.35624275],\n",
       "       [ 0.53882909],\n",
       "       [ 0.63341409],\n",
       "       [ 0.47135681],\n",
       "       [ 0.61958778],\n",
       "       [ 0.42561847],\n",
       "       [ 0.51211774],\n",
       "       [ 0.29424879],\n",
       "       [ 0.38310093],\n",
       "       [ 0.28851342],\n",
       "       [ 0.35126474],\n",
       "       [ 0.65281165],\n",
       "       [ 0.48659411],\n",
       "       [ 0.43335259],\n",
       "       [ 0.32977027],\n",
       "       [ 0.65944982],\n",
       "       [ 0.6016748 ],\n",
       "       [ 0.62601507]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.523416 %\n",
      "Recall: 0.786749 %\n",
      "Fscore: 0.560968 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
